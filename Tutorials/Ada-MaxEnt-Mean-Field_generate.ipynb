{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a46621-5a8e-4594-9b40-87ea8d948488",
   "metadata": {},
   "source": [
    "# Actualization Criteria and Self-Consistent Mean-Field Projections\n",
    "\n",
    "In this tutorial, we will build upon the concepts introduced in the previous tutorial, where we explored different actualization criteria for Adaptive Max-Ent. Notably, we discovered that the **Partial Sum criterion** provides the tightest control over errors, in contrast to the **Lieb-Robinson criterion**, which is lestightnt.  \n",
    "\n",
    "However, as the complexity of the bases involved in the actualization g linearly with the number of actualizations and with the depth of the basis, $\\ell$rows, managing this complexity becomes critical. To address this challenge, a Self-Consistent **Mean-Field (MF) projection** is applied, to reduce and organize the basis while retaining its essential features.  \n",
    "\n",
    "In this tutorial, we will continue the discussion while maintaining the same initial conditions for the system.  \n",
    "\n",
    "### Objectives:  \n",
    "\n",
    "We will introduce two examples of **MF-aided Adaptive Max-Ent simulations**:  \n",
    "1. The basis of observables is constructed as a **$m_0$-body projected Hierarchical Basis**, where the projection ensures that all elements of the basis remain manageable.  \n",
    "2. We will demonstrate how Mean-Field projections enable efficient simulations while preserving the accuracy of the Adaptive Max-Ent scheme.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb79225a-59df-49c0-984c-9cacb154e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "path= '../'\n",
    "sys.path.insert(1, path) \n",
    "\n",
    "### long term ev \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Configuration du style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,        # Taille de police\n",
    "    'axes.labelsize': 14,   # Taille des labels des axes\n",
    "    'axes.titlesize': 16,   # Taille des titres\n",
    "    'legend.fontsize': 12,  # Taille des légendes\n",
    "    'xtick.labelsize': 12,  # Taille des labels des ticks sur l'axe X\n",
    "    'ytick.labelsize': 12,  # Taille des labels des ticks sur l'axe Y\n",
    "    'font.family': 'serif', # Police de type \"serif\" pour un rendu professionnel\n",
    "    'axes.linewidth': 1.5,  # Largeur des bordures des axes\n",
    "    'grid.alpha': 0.5       # Transparence des grilles\n",
    "})\n",
    "\n",
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import qutip as qutip\n",
    "from typing import Callable, Optional, Tuple\n",
    "from scipy.optimize import root, fsolve\n",
    "\n",
    "\n",
    "from IPython.display import display_latex\n",
    "from alpsqutip.geometry import graph_from_alps_xml, list_graph_in_alps_xml\n",
    "from alpsqutip.alpsmodels import list_operators_in_alps_xml,model_from_alps_xml\n",
    "from alpsqutip.utils import eval_expr\n",
    "from alpsqutip.model import SystemDescriptor\n",
    "from alpsqutip import restricted_maxent_toolkit as me ## custom library including basic linear algebra functions \n",
    "from alpsqutip.proj_evol import safe_exp_and_normalize ## function used to safely and robustly map K-states to states\n",
    "from alpsqutip.operators.states.meanfield import one_body_from_qutip_operator, project_to_n_body_operator, self_consistent_quadratic_mfa\n",
    "from alpsqutip.qutip_tools.tools import project_qutip_to_m_body\n",
    "## functions used for Mean-Field projections\n",
    "\n",
    "\n",
    "\n",
    "def lieb_robinson_speed(parameters):\n",
    "    \"\"\"Compute the Lieb Robinson speed from the parameters\"\"\"\n",
    "    \n",
    "    f_factor=np.real(max(np.roots(np.poly1d([1, 0, \n",
    "                                             -(parameters['Jx']*parameters['Jy']+\n",
    "                                               parameters['Jx']*parameters['Jy']+\n",
    "                                               parameters['Jy']*parameters['Jz']), \n",
    "                                             -2*parameters['Jx']*parameters['Jy']*parameters['Jz']])\n",
    "                                 )\n",
    "                        )\n",
    "                    )\n",
    "    chi_y=fsolve(lambda x,y: x*np.arcsinh(x)-np.sqrt(x**2+1)-y, 1e-1, args=(0))[0]\n",
    "    return 4*f_factor*chi_y\n",
    "\n",
    "models_lib_file = \"../alpsqutip/lib/models.xml\"\n",
    "lattice_lib_file = \"../alpsqutip/lib/lattices.xml\"\n",
    "SIMULATIONS_FILE_PREFIX = \"simulations\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887fd342",
   "metadata": {},
   "source": [
    "# Load the set of previous simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6fc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we store the results of the simulations\n",
    "try:\n",
    "    with open(f\"{SIMULATIONS_FILE_PREFIX}.pkl\", \"br\") as in_file:\n",
    "        simulations = pickle.load(in_file)\n",
    "\n",
    "    with open(f\"{SIMULATIONS_FILE_PREFIX}_{str(datetime.now())}.bkp\", \"bw\") as out_file:\n",
    "        pickle.dump(simulations, out_file)\n",
    "except:\n",
    "    simulations = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d3498",
   "metadata": {},
   "source": [
    "# Define the system and objects required for the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf82b1c7-d693-4916-b27b-ce1cb0fb6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={}\n",
    "\n",
    "params['size']=7\n",
    "params['Jx']=1.; params['Jy'] = .75*params['Jx']; params['Jz']=1.05*params['Jx']\n",
    "params[\"phi0\"] = np.array([.0, .25, .25, -10.])    # No podemos ir más allá de |phi|< 10, \n",
    "                                                   # ya que la matriz de Gram se hace singular. \n",
    "\n",
    "vLR = lieb_robinson_speed(params)\n",
    "\n",
    "\n",
    "system=SystemDescriptor(\n",
    "    model=model_from_alps_xml(models_lib_file, \"spin\"),\n",
    "    graph=graph_from_alps_xml(lattice_lib_file, \"open chain lattice\", parms={\"L\":params['size'], \"a\":1}),\n",
    "    parms={\"h\":0,\"J\":params['Jx']}\n",
    ")\n",
    "\n",
    "sites=[s for s in system.sites]\n",
    "sx_ops=[system.site_operator(\"Sx\", '1[' + str(a) + ']') for a in range(len(system.sites))]\n",
    "sy_ops=[system.site_operator(\"Sy\", '1[' + str(a) + ']') for a in range(len(system.sites))]\n",
    "sz_ops=[system.site_operator(\"Sz\", '1[' + str(a) + ']') for a in range(len(system.sites))]\n",
    "\n",
    "H = (params['Jx']*sum(sx_ops[i]*sx_ops[i+1] for i in range(params['size']-1)) + params['Jy']*sum(sy_ops[i]*sy_ops[i+1] for i in range(params['size']-1))\n",
    "     +params['Jz']*sum(sz_ops[i]*sz_ops[i+1] for i in range(params['size']-1)))\n",
    "idop=system.site_operator(\"identity\", sites[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d16bbb",
   "metadata": {},
   "source": [
    "## Define the basis and the initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b9a3f9-0f1b-4998-b9cd-955f89c53ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49964270571677594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HBB0=[idop, system.site_operator('Sx', '1[0]'), system.site_operator('Sy', '1[0]'), system.site_operator('Sz', '1[0]')]\n",
    "\n",
    "phi0 = params[\"phi0\"]\n",
    "K0 = me.Kstate_from_phi_basis(phi0, HBB0)\n",
    "sigma0 = safe_exp_and_normalize(K0)[0]\n",
    "phi0[0] = np.log(sigma0.tr())\n",
    "K0 = me.Kstate_from_phi_basis(phi0, HBB0)\n",
    "sigma0 = safe_exp_and_normalize(K0)[0]\n",
    "[(sigma0 * op).tr() for op in sz_ops] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc087b9",
   "metadata": {},
   "source": [
    "## Define the observables we are going to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc537e8-d350-49e1-830a-d84b57b15ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVABLES = {\n",
    "\"obs_SzA\": (.5*qutip.tensor(qutip.sigmaz(),qutip.qeye(2),qutip.qeye(2))+\n",
    "            .5*qutip.tensor(qutip.qeye(2),qutip.sigmaz(),qutip.qeye(2))+\n",
    "            .5*qutip.tensor(qutip.qeye(2),qutip.qeye(2),qutip.sigmaz()),\n",
    "            [i for i in range(0,3)]\n",
    "           ),\n",
    "\"obs_Sx3Sx4\": ((sx_ops[2]*sy_ops[3]).to_qutip(), None)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timespan=np.linspace(.0, 650.1/vLR, 650)\n",
    "\n",
    "def estimate_error_by_partial_sum(phi_local, ws):\n",
    "    return me.m_th_partial_sum(phi=phi_local, m=2) / me.m_th_partial_sum(phi=phi_local, m=0)\n",
    "\n",
    "def estimate_error_by_weights(phi, ws):\n",
    "    return sum(abs(phi_a*w_a) for phi_a, w_a in zip(phi,ws))\n",
    "\n",
    "\n",
    "# Choose the error estimator\n",
    "# estimate_error = estimate_error_by_weights\n",
    "estimate_error = estimate_error_by_partial_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2080abc",
   "metadata": {},
   "source": [
    "## Check consistency and get the exact evolution \n",
    "* Verify that the parameters coincides with the parameters stored in the previous run. \n",
    "* Run the exact simulation if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f8abce-e223-47fc-8824-325caf9679dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## exact dynamics\n",
    "############# Uncomment the next line to start a new set of simulations\n",
    "## simulations = {}\n",
    "if \"_params\" in simulations:\n",
    "    stored_parms = simulations[\"_params\"]\n",
    "    for key in stored_parms:\n",
    "        if key == \"phi0\":\n",
    "            assert list(stored_parms[key]) == list(params[key])\n",
    "        else:\n",
    "            assert stored_parms[key] == params[key]\n",
    "    assert all(key in stored_parms for key in params), \"keys missing\"\n",
    "    # simulations[\"parms\"] = params\n",
    "else:\n",
    "    simulations[\"_params\"] = params\n",
    "    simulations[\"_observables\"] = OBSERVABLES\n",
    "\n",
    "    \n",
    "def run_exact_simulation(simulation):\n",
    "    expect_values = {key:[] for key in OBSERVABLES}\n",
    "    expect_values[\"time\"] = []\n",
    "    def callback_compute_obs(t, k):\n",
    "        rho, _ = safe_exp_and_normalize(k)\n",
    "        expect_values[\"time\"].append(t)\n",
    "        for key, obs_op_ss in OBSERVABLES.items():\n",
    "            op, ss = obs_op_ss\n",
    "            if ss is not None:\n",
    "                rho_loc = rho.ptrace(ss)\n",
    "                expect_values[key].append(np.real(qutip.expect(rho_loc, op)))\n",
    "            else:\n",
    "                expect_values[key].append(np.real(qutip.expect(rho, op)))\n",
    "        \n",
    "    \n",
    "    qutip.mesolve(H=H.to_qutip(), rho0=K0.to_qutip(), tlist=timespan,e_ops=callback_compute_obs)\n",
    "    simulation[\"ev_obs_ex\"] = expect_values\n",
    "    \n",
    "    \n",
    "if \"exact\" not in simulations:\n",
    "    print(\"solving the exact problem.\")\n",
    "    simulations[\"exact\"] = {\n",
    "        \"parms\":params,\n",
    "        \"date\": datetime.now(),\n",
    "        \"name\": \"exact\",\n",
    "        \"ev_obs_ex\":[],\n",
    "        \"times\": timespan,\n",
    "    } \n",
    "    run_exact_simulation(simulations[\"exact\"])\n",
    "    \n",
    "    with open(f\"{SIMULATIONS_FILE_PREFIX}.pkl\", \"bw\") as out_file:\n",
    "        pickle.dump(simulations, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f945e-2536-4082-8061-8d398a630e94",
   "metadata": {},
   "source": [
    "### Mean-Field Projections for Basis Construction\n",
    "To construct a new basis and compute the matrix elements of ${\\cal G}$ and ${\\cal H}$, it is necessary to approximate the instantaneous state ${\\sigma}(t) \\propto \\exp(-{\\bf K}(t))$. While exact computation of ${\\bf K}(t)$ is often impractical, except in special cases such as when ${\\bf K}(t)$ is a one-body operator, a suitable approximation suffices to compute the evolution.\n",
    "\n",
    "Mean-Field Approach Overview\n",
    "The Mean-Field (MF) approach is a widely used method in fields like condensed matter physics (e.g., superconductive models) and quantum information for simplifying complex systems. Its central idea is to approximate $n$-body interactions in a quantum system using effective one-body (or higher-order) averages.\n",
    "\n",
    "This approach can be formalized through Mean-Field projections:\n",
    "\n",
    "MF projections, denoted as $\\pi^{\\rm MF}_{B}: {\\cal A} \\rightarrow {\\cal A}_B$, map the full algebra of observables, ${\\cal A}$, to a subalgebra, ${\\cal A}B$, relative to a suitable basis $B{\\rm MF}$.\n",
    "For product-state MF, the basis $B_{\\rm MF} = B_{\\rm prod}$ consists of local observables, such that $B_{\\rm prod} = \\bigsqcup_i B_i$, where $B_i$ spans a local subalgebra ${\\cal A}_{B_i}$. The resulting Max-Ent states are product states: $\\sigma^{\\rm MF} = \\bigotimes_i \\sigma_i$.\n",
    "Similarly, bosonic and fermionic MF states can be defined using quadratic forms (e.g., creation and annihilation operators) with the basis $B_{\\rm MF} = B_{\\rm quad}$.\n",
    "Mean-Field Projection Formula\n",
    "The MF projection of an observable ${\\bf O}$ is given by:\n",
    "\n",
    "$$\\pi^{\\rm MF}_{\\tilde{B}, \\sigma^{\\rm MF}}({\\bf O}) = \\sum_{{\\bf Q} \\in \\tilde{B}} \\big({\\bf Q} - \\langle {\\bf Q} \\rangle_{\\sigma^{\\rm MF}}\\big) \n",
    "    \\frac{\\partial \\langle {\\bf O} \\rangle_{\\sigma^{\\rm MF}}}{\\partial \\langle {\\bf Q} \\rangle_{\\sigma^{\\rm MF}}} \n",
    "    + \\langle {\\bf O} \\rangle_{\\sigma^{\\rm MF}}$$\n",
    "    \n",
    "This projection ensures consistency with the mean-field state, $\\sigma^{\\rm MF}$.\n",
    "\n",
    "The mean-field state, $\\sigma^{\\rm MF}$, satisfies the self-consistent equation:\n",
    "\n",
    "$$\\sigma^{\\rm MF} = \\frac{\\exp(- \\pi^{\\rm MF}_{\\tilde{B}, \\sigma^{\\rm MF}}({\\bf O}))}{{\\rm Tr} \\exp(- \\pi^{\\rm MF}_{\\tilde{B}, \\sigma^{\\rm MF}}({\\bf O}))}$$\n",
    "\n",
    "The MF projection $\\sigma^{\\rm MF} = \\exp(-\\tilde{\\bf K})$ of a state $\\exp(-{\\bf K})$ can be computed iteratively using:\n",
    "\n",
    "$$\\tilde{\\bf K}^{(i+1)} = \\pi^{\\rm MF}_{\\tilde{B}, \\sigma_i^{\\rm MF}}({\\bf K})$$\n",
    "\n",
    "Here, $\\sigma_i^{\\rm MF} = \\exp(-\\tilde{\\bf K}^{(i)})$, and the initial guess $\\sigma^{\\rm MF (0)}$ can be the system's initial state $\\sigma(0)$ or a prior MF state $\\sigma^{\\rm MF}(T_{n-1})$.\n",
    "\n",
    "#### Benefits and Challenges\n",
    "Advantages: The self-consistent MF approach often converges rapidly, providing manageable approximations of complex states.\n",
    "\n",
    "Caveats: In ill-conditioned scenarios, convergence may fail or lead to non-trivial fixed points, requiring further refinements beyond this method's scope.\n",
    "\n",
    "### Modified Hierarchical Basis  \n",
    "\n",
    "The **Modified Hierarchical Basis** is constructed from the evolved state just before actualization. This state is then projected onto $m_0$-body observables, ensuring that the basis remains efficient and adapted to the system's current dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c92b69-02e1-430b-a266-d8c1e42d3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_maxent_simulation(current_simulation):\n",
    "    \"\"\"\n",
    "    Run the simulation of a Max-Ent dynamic.\n",
    "    Results are stored as entries in `current_simulation`. \n",
    "    \"\"\"\n",
    "    current_simulation_parms = current_simulation[\"parms\"]\n",
    "    chosen_depth = current_simulation_parms[\"chosen_depth\"]\n",
    "    eps_tol = current_simulation_parms[\"eps\"]\n",
    "    m0 = current_simulation_parms[\"m0\"]\n",
    "\n",
    "\n",
    "    # Initialize variables to track errors, saved cut times, expectation values, and commutators\n",
    "    actualizations = 0\n",
    "    bases_deep = 0\n",
    "    \n",
    "    saved_cut_times_index_ell = current_simulation.setdefault(\"saved_cut_times_index_ell\",[0])  \n",
    "    ev_obs_maxent = current_simulation.setdefault(\"ev_obs_maxent\",{key:[] for key in OBSERVABLES})\n",
    "    ev_obs_maxent[\"time\"] = []\n",
    "    no_acts_ell = current_simulation.setdefault(\"no_acts_ell\",[0])\n",
    "    number_of_commutators_ell = current_simulation.setdefault(\"number_of_commutators_ell\", [])\n",
    "\n",
    "\n",
    "    # to be used in storing the values of the partial sum at File ~/.conda/envs/jupyter/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:377, in _ArpackParams._raise_no_convergence(self)each time\n",
    "    local_bound_error_ell = current_simulation.setdefault(\"local_bound_error_ell\",[])\n",
    "    # to be used in storing the spectral norm of the Hij tensor at each actualization of the (orthonormalized) basis\n",
    "    spectral_norm_Hij_tensor_ell=current_simulation.setdefault(\"spectral_norm_Hij_tensor_ell\",[])\n",
    "    # Norm of the orthogonal component of the commutators\n",
    "    instantaneous_w_errors =  current_simulation.setdefault(\"instantaneous_w_errors\",[])\n",
    "\n",
    "\n",
    "    # Start the computation\n",
    "\n",
    "    def callback_compute_obs_maxent(t, rho):\n",
    "        ev_obs_maxent[\"time\"].append(t)\n",
    "        for key, obs_op_ss in OBSERVABLES.items():\n",
    "            op, ss = obs_op_ss\n",
    "            if ss is not None:\n",
    "                rho_loc = rho.ptrace(ss)\n",
    "                ev_obs_maxent[key].append(qutip.expect(rho_loc, op))\n",
    "            else:\n",
    "                ev_obs_maxent[key].append(qutip.expect(rho, op))\n",
    "\n",
    "    # Compute the initial observables\n",
    "    callback_compute_obs_maxent(0, sigma0.to_qutip())\n",
    "\n",
    "    # Compute the scalar product operator used for orthogonalization\n",
    "    sp_local = me.fetch_covar_scalar_product(sigma=sigma0.to_qutip()); local_t_value = .0  \n",
    "\n",
    "    # Build the initial Krylov basis and orthogonalize it\n",
    "    HBB_ell_act = me.build_Hierarch(generator=H.to_qutip(), seed_op=K0.to_qutip(), deep=chosen_depth)  \n",
    "    orth_basis_act = me.orthogonalize_basis(basis=HBB_ell_act, sp=sp_local)\n",
    "    bases_deep = len(orth_basis_act)\n",
    "    number_of_commutators_ell.append(bases_deep)\n",
    "\n",
    "    # Compute the Hamiltonian tensor for the basis\n",
    "    Hij_tensor_act, w_errors = me.fn_Hij_tensor_with_errors(generator=H.to_qutip(), basis=orth_basis_act, sp=sp_local)\n",
    "    instantaneous_w_errors.append(np.real(w_errors))\n",
    "\n",
    "    spectral_norm_Hij_tensor_ell.append(linalg.norm(Hij_tensor_act))\n",
    "\n",
    "    # Initial condition\n",
    "    phi0_proj_act = me.project_op(K0.to_qutip(), orth_basis_act, sp_local)  \n",
    "\n",
    "    # Initialize lists to store time-evolved values\n",
    "    phi_at_timet = [phi0_proj_act]  \n",
    "    K_at_timet = [K0.to_qutip()]  \n",
    "    sigma_at_timet = [me.safe_expm_and_normalize(K_at_timet[0])]  \n",
    "\n",
    "    # Iterate through the time steps\n",
    "    for t in timespan[1:]:\n",
    "        print(\"t=\", t)\n",
    "        # Evolve the state phi(t) for a small time window\n",
    "        phi_local = np.real(linalg.expm(Hij_tensor_act * (t - local_t_value)) @ phi0_proj_act)  \n",
    "\n",
    "        # Compute the new K-state from the orthogonal basis and phi(t)\n",
    "        K_local = me.Kstate_from_phi_basis(phi=-phi_local, basis=orth_basis_act)  \n",
    "\n",
    "        # Normalize to obtain the updated density matrix sigma(t)\n",
    "        sigma_local = safe_exp_and_normalize(K_local)[0]  \n",
    "\n",
    "        # Record expectation values of the observable\n",
    "        callback_compute_obs_maxent(t, sigma_local)\n",
    "\n",
    "        # Calculate the local error bound using partial sums\n",
    "        local_bound_error_ell.append(estimate_error(phi_local, w_errors))  \n",
    "\n",
    "        # Check if the local error exceeds the threshold\n",
    "        if abs(local_bound_error_ell[-1]) >= eps_tol:\n",
    "            print(\"   error bound=\", local_bound_error_ell[-1],\n",
    "                  f\".\\n  Updating basis with deep {chosen_depth}\",  datetime.now())\n",
    "            # If positive, perform actualization\n",
    "            actualizations = actualizations + 1\n",
    "\n",
    "            # Log errors at specific intervals for debugging\n",
    "            if list(timespan).index(t) % 50 == 0:  \n",
    "                print(\"error\", t)  \n",
    "\n",
    "            # Update the local time value and save the cut time index\n",
    "            local_t_value = t  \n",
    "            saved_cut_times_index_ell.append(list(timespan).index(t))  \n",
    "\n",
    "            # Map the K-local state onto a Mean-Field state, retaining only its one-body correlations, to be used in sp\n",
    "            K_act, sigma_act=me.mft_state_it(K_local, sigma_local, max_it=10)\n",
    "            sigma_act=sigma_act.to_qutip()\n",
    "\n",
    "            # Recompute the scalar product using the MF state\n",
    "            sp_local = me.fetch_covar_scalar_product(sigma=sigma_act)  \n",
    "\n",
    "            # The new basis is spanned from the K_local state\n",
    "            HBB_ell_act = me.build_Hierarch(generator=H.to_qutip(), seed_op=K_local, deep=chosen_depth)  \n",
    "\n",
    "            # The growth in complexity of the basis is arrested by projecting this basis onto simpler basis\n",
    "            # composed of $nmax$-body observables only, with $nmax$ much smaller than the size of the system. \n",
    "            local_states = [sigma_act.ptrace([i]) for i, _ in enumerate(sigma_act.dims[0])]\n",
    "            \n",
    "            print(f\"      * project to {m0}-bodies\")\n",
    "            HBB_ell_act=[project_qutip_to_m_body(op, m0, local_states) \n",
    "                         for op in HBB_ell_act]\n",
    "\n",
    "            print(f\"      * orthogonalizing\")\n",
    "            orth_basis_act = me.orthogonalize_basis(basis=HBB_ell_act, sp=sp_local)  \n",
    "            bases_deep = len(orth_basis_act)\n",
    "\n",
    "            # Recompute the Hamiltonian tensor and project the state\n",
    "            print(f\"      * building H\")\n",
    "            Hij_tensor_act, w_errors = me.fn_Hij_tensor_with_errors(generator=H.to_qutip(), basis=orth_basis_act, sp=sp_local)  \n",
    "            print(f\"    bases updated with a depth of {bases_deep}\", datetime.now())\n",
    "            instantaneous_w_errors.append(np.real(w_errors))\n",
    "            spectral_norm_Hij_tensor_ell.append(linalg.norm(Hij_tensor_act))\n",
    "            phi0_proj_act = me.project_op(K_local, orth_basis_act, sp_local)  \n",
    "\n",
    "        number_of_commutators_ell.append(number_of_commutators_ell[-1])  \n",
    "        no_acts_ell.append(actualizations)\n",
    "\n",
    "    current_simulation[\"velocity_mu_ell\"] = np.array(simulation[\"spectral_norm_Hij_tensor_ell\"])\n",
    "    times_act_ell  = np.array(simulation[\"saved_cut_times_index_ell\"])\n",
    "    current_simulation[\"times_act_ell\"] = times_act_ell\n",
    "    current_simulation[\"velocity_PS_ell\"] = np.array([1/(times_act_ell[i+1]-times_act_ell[i]) \n",
    "                                                      for i in range(len(times_act_ell)-1)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f9b66-6f0e-46ad-bdd1-33d3ecbd9b90",
   "metadata": {},
   "source": [
    "### Test the simulation with different choices of the parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa29342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation (3,5,0.1,weights)\n",
      "t= 0.09318898351278253\n",
      "t= 0.18637796702556506\n",
      "t= 0.27956695053834757\n",
      "t= 0.3727559340511301\n",
      "t= 0.46594491756391265\n",
      "t= 0.5591339010766951\n",
      "t= 0.6523228845894777\n",
      "t= 0.7455118681022602\n",
      "t= 0.8387008516150427\n",
      "t= 0.9318898351278253\n",
      "t= 1.025078818640608\n",
      "t= 1.1182678021533903\n",
      "t= 1.2114567856661729\n",
      "t= 1.3046457691789555\n",
      "t= 1.3978347526917378\n",
      "   error bound= 0.12676186162768677 .\n",
      "  Updating basis with deep 5 2024-12-20 07:10:25.300996\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 07:14:50.635295\n",
      "t= 1.4910237362045204\n",
      "   error bound= 0.5631186556269612 .\n",
      "  Updating basis with deep 5 2024-12-20 07:14:50.769304\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 07:21:34.017287\n",
      "t= 1.584212719717303\n",
      "   error bound= 0.5508808154670944 .\n",
      "  Updating basis with deep 5 2024-12-20 07:21:34.090905\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 07:28:44.613846\n",
      "t= 1.6774017032300854\n",
      "   error bound= 0.5823939998295119 .\n",
      "  Updating basis with deep 5 2024-12-20 07:28:44.714728\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 07:36:00.038972\n",
      "t= 1.770590686742868\n",
      "   error bound= 0.6181477769237091 .\n",
      "  Updating basis with deep 5 2024-12-20 07:36:00.115934\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 07:43:13.178585\n",
      "t= 1.8637796702556506\n",
      "   error bound= 0.657987221081424 .\n",
      "  Updating basis with deep 5 2024-12-20 07:43:13.310991\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 07:50:36.642592\n",
      "t= 1.956968653768433\n",
      "   error bound= 0.7013428608117269 .\n",
      "  Updating basis with deep 5 2024-12-20 07:50:36.719195\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 07:58:03.823897\n",
      "t= 2.050157637281216\n",
      "   error bound= 0.7474674026117286 .\n",
      "  Updating basis with deep 5 2024-12-20 07:58:03.899570\n",
      "      * project to 3-bodies\n",
      "      * orthogonalizing\n",
      "      * building H\n",
      "    bases updated with a depth of 6 2024-12-20 08:05:19.950277\n",
      "t= 2.143346620793998\n",
      "   error bound= 0.7956826332838756 .\n",
      "  Updating basis with deep 5 2024-12-20 08:05:20.027014\n",
      "      * project to 3-bodies\n"
     ]
    }
   ],
   "source": [
    "cases = []\n",
    "for m0 in [3,2,1]:\n",
    "    for depth in [5, 3]:\n",
    "        for epstol in [.1,.01,.001]: \n",
    "            cases.append({\n",
    "                    'm0':m0,\n",
    "                    'chosen_depth':depth,\n",
    "                    'eps':epstol,\n",
    "                })\n",
    "\n",
    "for estimate_error in (estimate_error_by_weights, estimate_error_by_partial_sum):\n",
    "    for approx_parms in cases:\n",
    "        simulation_name = f\"({approx_parms['m0']},{approx_parms['chosen_depth']},{approx_parms['eps']},{repr(estimate_error)[28:][:-19]})\"\n",
    "        simulations[simulation_name] = {\n",
    "            \"parms\":approx_parms,\n",
    "            \"date\": datetime.now(),\n",
    "            \"name\": simulation_name,\n",
    "        } \n",
    "        try:\n",
    "            print(\"Simulation\", simulation_name)\n",
    "            run_maxent_simulation(simulations[simulation_name])\n",
    "        except linalg.ArpackNoConvergence:\n",
    "            continue\n",
    "\n",
    "        with open(f\"{SIMULATIONS_FILE_PREFIX}.pkl\", \"bw\") as out_file:\n",
    "            pickle.dump(simulations, out_file)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
